{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Logistic Regression vs Random Forest Classifier model in determining credit risk\n",
    "\n",
    "#### Prediction: \n",
    "Logistic regression will out-perform the Random Forest model because the dataset is relatively simple and does not contain an overwhelming number of noise variables. \n",
    "\n",
    "#### Results:\n",
    " As predicted, logistic regression performed with a higher average accuracy score *[0.9937 or 99.37%]* compared to the random forest classifier model, which yielded *0.9915 (99.15% accuracy rate)*. \n",
    " Given the slim dataset, it is likely unwise to further reduce its complexity through methods such as feature selection. Doing so may increase overfitting risk and ultimately reduce the overall accuracy of the models, as attested by the values returned by <code>test_model_fs()</code>.\n",
    "\n",
    " The accuracy of the logistic regression model was improved *[to 0.9943 or 99.43%]* by tuning its hyper parameters with <code>test_model_param()</code>, which uses the <code>RandomizedSearchCV</code> method from scikit-learn to perform a randomized search on input hyper parameter ranges.\n",
    " \n",
    "Increasing the number of estimators(trees) from 100 to 1000 in the random forest classifier model yielded slightly higher nominal scores for accuracy *(+0.015%)*: *0.99153* and *0.99169* respectively. \n",
    "\n",
    "#### Further analysis:\n",
    "A two-sample pairwise t-test could be performed to quantify the statistical significance of the differences in performance metrics between the two models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_size</th>\n",
       "      <th>interest_rate</th>\n",
       "      <th>borrower_income</th>\n",
       "      <th>debt_to_income</th>\n",
       "      <th>num_of_accounts</th>\n",
       "      <th>derogatory_marks</th>\n",
       "      <th>total_debt</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.672</td>\n",
       "      <td>52800</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8400.0</td>\n",
       "      <td>6.692</td>\n",
       "      <td>43600</td>\n",
       "      <td>0.311927</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9000.0</td>\n",
       "      <td>6.963</td>\n",
       "      <td>46100</td>\n",
       "      <td>0.349241</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>16100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10700.0</td>\n",
       "      <td>7.664</td>\n",
       "      <td>52700</td>\n",
       "      <td>0.430740</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10800.0</td>\n",
       "      <td>7.698</td>\n",
       "      <td>53000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>23000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_size  interest_rate  borrower_income  debt_to_income  num_of_accounts  \\\n",
       "0    10700.0          7.672            52800        0.431818                5   \n",
       "1     8400.0          6.692            43600        0.311927                3   \n",
       "2     9000.0          6.963            46100        0.349241                3   \n",
       "3    10700.0          7.664            52700        0.430740                5   \n",
       "4    10800.0          7.698            53000        0.433962                5   \n",
       "\n",
       "   derogatory_marks  total_debt  loan_status  \n",
       "0                 1       22800            0  \n",
       "1                 0       13600            0  \n",
       "2                 0       16100            0  \n",
       "3                 1       22700            0  \n",
       "4                 1       23000            0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "df = pd.read_csv(\"Resources/lending_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing values\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data without the target column and the target variable\n",
    "# converting data to an array circumvents user warning during fitting.\n",
    "X = df.drop(['loan_status'], axis=1).to_numpy()\n",
    "y = df['loan_status'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0700e+04, 7.6720e+00, 5.2800e+04, ..., 5.0000e+00, 1.0000e+00,\n",
       "        2.2800e+04],\n",
       "       [8.4000e+03, 6.6920e+00, 4.3600e+04, ..., 3.0000e+00, 0.0000e+00,\n",
       "        1.3600e+04],\n",
       "       [9.0000e+03, 6.9630e+00, 4.6100e+04, ..., 3.0000e+00, 0.0000e+00,\n",
       "        1.6100e+04],\n",
       "       ...,\n",
       "       [1.7600e+04, 1.0595e+01, 8.0300e+04, ..., 1.1000e+01, 2.0000e+00,\n",
       "        5.0300e+04],\n",
       "       [1.6300e+04, 1.0068e+01, 7.5300e+04, ..., 1.0000e+01, 2.0000e+00,\n",
       "        4.5300e+04],\n",
       "       [1.5600e+04, 9.7420e+00, 7.2300e+04, ..., 9.0000e+00, 2.0000e+00,\n",
       "        4.2300e+04]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, X, y, seed=5):\n",
    "    \"\"\"inputs model class and prints out train/test average accuracy scores\n",
    "\n",
    "    Args:\n",
    "        model (class): model class name\n",
    "        X (dataframe): data without label column\n",
    "        y (1D series): label data\n",
    "        seed (int): random seed value; default=5\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed)\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    clf = model.fit(X_train_scaled, y_train)\n",
    "    print(f\"model: {type(clf).__name__}, seed:{seed}\")\n",
    "    print(f\"train score: {clf.score(X_train_scaled, y_train)}\")\n",
    "    print(f\"test score: {clf.score(X_test_scaled, y_test)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_param(param_grid, model, X, y, seed=5):\n",
    "    \"\"\"inputs model class and a dictionary of hyper parameter ranges and prints out the best hyper parameters and accuracy score\n",
    "\n",
    "    Args:\n",
    "        param_grid (dict): parameter object for the RandomizedSearchCV estimator\n",
    "        model (class): model class name\n",
    "        X (dataframe): data without label column\n",
    "        y (1D series): label data\n",
    "        seed (int): random seed value; default=5\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed)\n",
    "    \n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    random_clf = RandomizedSearchCV(model, param_grid, random_state=42, verbose=0)\n",
    "    random_clf.fit(X_train_scaled, y_train)\n",
    "    print(f\"model: {type(model).__name__}, seed:{seed}\")\n",
    "    print(f\"best parameters: {random_clf.best_params_}\")\n",
    "    print(f\"test score: {random_clf.best_score_} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_fs(model, X, y, seed=5):\n",
    "    \"\"\"uses feature selection to reduce data width and prints out train/test accuracy scores\n",
    "    Args:\n",
    "        model (class): sklearn model class name\n",
    "        X (dataframe): data without label column\n",
    "        y (1D series): label data\n",
    "        seed (int): random seed value; default=5\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed)\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train_scaled = scaler.transform(X_train)\n",
    "    clf = model\n",
    "    \n",
    "    sel = SelectFromModel(clf)\n",
    "    sel.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    X_sel_train, X_sel_test, y_train, y_test = train_test_split(sel.transform(X), y, random_state=seed)\n",
    "    scaler = StandardScaler().fit(X_sel_train)\n",
    "    X_sel_train_scaled = scaler.transform(X_sel_train)\n",
    "    X_sel_test_scaled = scaler.transform(X_sel_test)\n",
    "    clf.fit(X_sel_train_scaled, y_train)\n",
    "    \n",
    "    print(f\"model (fs): {type(clf).__name__}, seed:{seed}\")\n",
    "    print(f\"train score: {clf.score(X_sel_train_scaled, y_train)}\")\n",
    "    print(f\"test score: {clf.score(X_sel_test_scaled, y_test)} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "        0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2 , 0.21,\n",
       "        0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 , 0.31, 0.32,\n",
       "        0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4 , 0.41, 0.42, 0.43,\n",
       "        0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5 , 0.51, 0.52, 0.53, 0.54,\n",
       "        0.55, 0.56, 0.57, 0.58, 0.59, 0.6 , 0.61, 0.62, 0.63, 0.64, 0.65,\n",
       "        0.66, 0.67, 0.68, 0.69, 0.7 , 0.71, 0.72, 0.73, 0.74, 0.75, 0.76,\n",
       "        0.77, 0.78, 0.79, 0.8 , 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87,\n",
       "        0.88, 0.89, 0.9 , 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98,\n",
       "        0.99, 1.  , 1.01, 1.02, 1.03, 1.04, 1.05, 1.06, 1.07, 1.08, 1.09,\n",
       "        1.1 , 1.11, 1.12, 1.13, 1.14, 1.15, 1.16, 1.17, 1.18, 1.19, 1.2 ,\n",
       "        1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.29, 1.3 , 1.31,\n",
       "        1.32, 1.33, 1.34, 1.35, 1.36, 1.37, 1.38, 1.39, 1.4 , 1.41, 1.42,\n",
       "        1.43, 1.44, 1.45, 1.46, 1.47, 1.48, 1.49, 1.5 , 1.51, 1.52, 1.53,\n",
       "        1.54, 1.55, 1.56, 1.57, 1.58, 1.59, 1.6 , 1.61, 1.62, 1.63, 1.64,\n",
       "        1.65, 1.66, 1.67, 1.68, 1.69, 1.7 , 1.71, 1.72, 1.73, 1.74, 1.75,\n",
       "        1.76, 1.77, 1.78, 1.79, 1.8 , 1.81, 1.82, 1.83, 1.84, 1.85, 1.86,\n",
       "        1.87, 1.88, 1.89, 1.9 , 1.91, 1.92, 1.93, 1.94, 1.95, 1.96, 1.97,\n",
       "        1.98, 1.99, 2.  , 2.01, 2.02, 2.03, 2.04, 2.05, 2.06, 2.07, 2.08,\n",
       "        2.09, 2.1 , 2.11, 2.12, 2.13, 2.14, 2.15, 2.16, 2.17, 2.18, 2.19,\n",
       "        2.2 , 2.21, 2.22, 2.23, 2.24, 2.25, 2.26, 2.27, 2.28, 2.29, 2.3 ,\n",
       "        2.31, 2.32, 2.33, 2.34, 2.35, 2.36, 2.37, 2.38, 2.39, 2.4 , 2.41,\n",
       "        2.42, 2.43, 2.44, 2.45, 2.46, 2.47, 2.48, 2.49, 2.5 , 2.51, 2.52,\n",
       "        2.53, 2.54, 2.55, 2.56, 2.57, 2.58, 2.59, 2.6 , 2.61, 2.62, 2.63,\n",
       "        2.64, 2.65, 2.66, 2.67, 2.68, 2.69, 2.7 , 2.71, 2.72, 2.73, 2.74,\n",
       "        2.75, 2.76, 2.77, 2.78, 2.79, 2.8 , 2.81, 2.82, 2.83, 2.84, 2.85,\n",
       "        2.86, 2.87, 2.88, 2.89, 2.9 , 2.91, 2.92, 2.93, 2.94, 2.95, 2.96,\n",
       "        2.97, 2.98, 2.99, 3.  , 3.01, 3.02, 3.03, 3.04, 3.05, 3.06, 3.07,\n",
       "        3.08, 3.09, 3.1 , 3.11, 3.12, 3.13, 3.14, 3.15, 3.16, 3.17, 3.18,\n",
       "        3.19, 3.2 , 3.21, 3.22, 3.23, 3.24, 3.25, 3.26, 3.27, 3.28, 3.29,\n",
       "        3.3 , 3.31, 3.32, 3.33, 3.34, 3.35, 3.36, 3.37, 3.38, 3.39, 3.4 ,\n",
       "        3.41, 3.42, 3.43, 3.44, 3.45, 3.46, 3.47, 3.48, 3.49, 3.5 , 3.51,\n",
       "        3.52, 3.53, 3.54, 3.55, 3.56, 3.57, 3.58, 3.59, 3.6 , 3.61, 3.62,\n",
       "        3.63, 3.64, 3.65, 3.66, 3.67, 3.68, 3.69, 3.7 , 3.71, 3.72, 3.73,\n",
       "        3.74, 3.75, 3.76, 3.77, 3.78, 3.79, 3.8 , 3.81, 3.82, 3.83, 3.84,\n",
       "        3.85, 3.86, 3.87, 3.88, 3.89, 3.9 , 3.91, 3.92, 3.93, 3.94, 3.95,\n",
       "        3.96, 3.97, 3.98, 3.99, 4.  , 4.01, 4.02, 4.03, 4.04, 4.05, 4.06,\n",
       "        4.07, 4.08, 4.09, 4.1 , 4.11, 4.12, 4.13, 4.14, 4.15, 4.16, 4.17,\n",
       "        4.18, 4.19, 4.2 , 4.21, 4.22, 4.23, 4.24, 4.25, 4.26, 4.27, 4.28,\n",
       "        4.29, 4.3 , 4.31, 4.32, 4.33, 4.34, 4.35, 4.36, 4.37, 4.38, 4.39,\n",
       "        4.4 , 4.41, 4.42, 4.43, 4.44, 4.45, 4.46, 4.47, 4.48, 4.49, 4.5 ,\n",
       "        4.51, 4.52, 4.53, 4.54, 4.55, 4.56, 4.57, 4.58, 4.59, 4.6 , 4.61,\n",
       "        4.62, 4.63, 4.64, 4.65, 4.66, 4.67, 4.68, 4.69, 4.7 , 4.71, 4.72,\n",
       "        4.73, 4.74, 4.75, 4.76, 4.77, 4.78, 4.79, 4.8 , 4.81, 4.82, 4.83,\n",
       "        4.84, 4.85, 4.86, 4.87, 4.88, 4.89, 4.9 , 4.91, 4.92, 4.93, 4.94,\n",
       "        4.95, 4.96, 4.97, 4.98, 4.99, 5.  , 5.01, 5.02, 5.03, 5.04, 5.05,\n",
       "        5.06, 5.07, 5.08, 5.09, 5.1 , 5.11, 5.12, 5.13, 5.14, 5.15, 5.16,\n",
       "        5.17, 5.18, 5.19, 5.2 , 5.21, 5.22, 5.23, 5.24, 5.25, 5.26, 5.27,\n",
       "        5.28, 5.29, 5.3 , 5.31, 5.32, 5.33, 5.34, 5.35, 5.36, 5.37, 5.38,\n",
       "        5.39, 5.4 , 5.41, 5.42, 5.43, 5.44, 5.45, 5.46, 5.47, 5.48, 5.49,\n",
       "        5.5 , 5.51, 5.52, 5.53, 5.54, 5.55, 5.56, 5.57, 5.58, 5.59, 5.6 ,\n",
       "        5.61, 5.62, 5.63, 5.64, 5.65, 5.66, 5.67, 5.68, 5.69, 5.7 , 5.71,\n",
       "        5.72, 5.73, 5.74, 5.75, 5.76, 5.77, 5.78, 5.79, 5.8 , 5.81, 5.82,\n",
       "        5.83, 5.84, 5.85, 5.86, 5.87, 5.88, 5.89, 5.9 , 5.91, 5.92, 5.93,\n",
       "        5.94, 5.95, 5.96, 5.97, 5.98, 5.99, 6.  , 6.01, 6.02, 6.03, 6.04,\n",
       "        6.05, 6.06, 6.07, 6.08, 6.09, 6.1 , 6.11, 6.12, 6.13, 6.14, 6.15,\n",
       "        6.16, 6.17, 6.18, 6.19, 6.2 , 6.21, 6.22, 6.23, 6.24, 6.25, 6.26,\n",
       "        6.27, 6.28, 6.29, 6.3 , 6.31, 6.32, 6.33, 6.34, 6.35, 6.36, 6.37,\n",
       "        6.38, 6.39, 6.4 , 6.41, 6.42, 6.43, 6.44, 6.45, 6.46, 6.47, 6.48,\n",
       "        6.49, 6.5 , 6.51, 6.52, 6.53, 6.54, 6.55, 6.56, 6.57, 6.58, 6.59,\n",
       "        6.6 , 6.61, 6.62, 6.63, 6.64, 6.65, 6.66, 6.67, 6.68, 6.69, 6.7 ,\n",
       "        6.71, 6.72, 6.73, 6.74, 6.75, 6.76, 6.77, 6.78, 6.79, 6.8 , 6.81,\n",
       "        6.82, 6.83, 6.84, 6.85, 6.86, 6.87, 6.88, 6.89, 6.9 , 6.91, 6.92,\n",
       "        6.93, 6.94, 6.95, 6.96, 6.97, 6.98, 6.99, 7.  , 7.01, 7.02, 7.03,\n",
       "        7.04, 7.05, 7.06, 7.07, 7.08, 7.09, 7.1 , 7.11, 7.12, 7.13, 7.14,\n",
       "        7.15, 7.16, 7.17, 7.18, 7.19, 7.2 , 7.21, 7.22, 7.23, 7.24, 7.25,\n",
       "        7.26, 7.27, 7.28, 7.29, 7.3 , 7.31, 7.32, 7.33, 7.34, 7.35, 7.36,\n",
       "        7.37, 7.38, 7.39, 7.4 , 7.41, 7.42, 7.43, 7.44, 7.45, 7.46, 7.47,\n",
       "        7.48, 7.49, 7.5 , 7.51, 7.52, 7.53, 7.54, 7.55, 7.56, 7.57, 7.58,\n",
       "        7.59, 7.6 , 7.61, 7.62, 7.63, 7.64, 7.65, 7.66, 7.67, 7.68, 7.69,\n",
       "        7.7 , 7.71, 7.72, 7.73, 7.74, 7.75, 7.76, 7.77, 7.78, 7.79, 7.8 ,\n",
       "        7.81, 7.82, 7.83, 7.84, 7.85, 7.86, 7.87, 7.88, 7.89, 7.9 , 7.91,\n",
       "        7.92, 7.93, 7.94, 7.95, 7.96, 7.97, 7.98, 7.99, 8.  , 8.01, 8.02,\n",
       "        8.03, 8.04, 8.05, 8.06, 8.07, 8.08, 8.09, 8.1 , 8.11, 8.12, 8.13,\n",
       "        8.14, 8.15, 8.16, 8.17, 8.18, 8.19, 8.2 , 8.21, 8.22, 8.23, 8.24,\n",
       "        8.25, 8.26, 8.27, 8.28, 8.29, 8.3 , 8.31, 8.32, 8.33, 8.34, 8.35,\n",
       "        8.36, 8.37, 8.38, 8.39, 8.4 , 8.41, 8.42, 8.43, 8.44, 8.45, 8.46,\n",
       "        8.47, 8.48, 8.49, 8.5 , 8.51, 8.52, 8.53, 8.54, 8.55, 8.56, 8.57,\n",
       "        8.58, 8.59, 8.6 , 8.61, 8.62, 8.63, 8.64, 8.65, 8.66, 8.67, 8.68,\n",
       "        8.69, 8.7 , 8.71, 8.72, 8.73, 8.74, 8.75, 8.76, 8.77, 8.78, 8.79,\n",
       "        8.8 , 8.81, 8.82, 8.83, 8.84, 8.85, 8.86, 8.87, 8.88, 8.89, 8.9 ,\n",
       "        8.91, 8.92, 8.93, 8.94, 8.95, 8.96, 8.97, 8.98, 8.99, 9.  , 9.01,\n",
       "        9.02, 9.03, 9.04, 9.05, 9.06, 9.07, 9.08, 9.09, 9.1 , 9.11, 9.12,\n",
       "        9.13, 9.14, 9.15, 9.16, 9.17, 9.18, 9.19, 9.2 , 9.21, 9.22, 9.23,\n",
       "        9.24, 9.25, 9.26, 9.27, 9.28, 9.29, 9.3 , 9.31, 9.32, 9.33, 9.34,\n",
       "        9.35, 9.36, 9.37, 9.38, 9.39, 9.4 , 9.41, 9.42, 9.43, 9.44, 9.45,\n",
       "        9.46, 9.47, 9.48, 9.49, 9.5 , 9.51, 9.52, 9.53, 9.54, 9.55, 9.56,\n",
       "        9.57, 9.58, 9.59, 9.6 , 9.61, 9.62, 9.63, 9.64, 9.65, 9.66, 9.67,\n",
       "        9.68, 9.69, 9.7 , 9.71, 9.72, 9.73, 9.74, 9.75, 9.76, 9.77, 9.78,\n",
       "        9.79, 9.8 , 9.81, 9.82, 9.83, 9.84, 9.85, 9.86, 9.87, 9.88, 9.89,\n",
       "        9.9 , 9.91, 9.92, 9.93, 9.94, 9.95, 9.96, 9.97, 9.98, 9.99]),\n",
       " 'tol': array([0.0e+00, 1.0e-05, 2.0e-05, 3.0e-05, 4.0e-05, 5.0e-05, 6.0e-05,\n",
       "        7.0e-05, 8.0e-05, 9.0e-05, 1.0e-04, 1.1e-04, 1.2e-04, 1.3e-04,\n",
       "        1.4e-04, 1.5e-04, 1.6e-04, 1.7e-04, 1.8e-04, 1.9e-04, 2.0e-04,\n",
       "        2.1e-04, 2.2e-04, 2.3e-04, 2.4e-04, 2.5e-04, 2.6e-04, 2.7e-04,\n",
       "        2.8e-04, 2.9e-04, 3.0e-04, 3.1e-04, 3.2e-04, 3.3e-04, 3.4e-04,\n",
       "        3.5e-04, 3.6e-04, 3.7e-04, 3.8e-04, 3.9e-04, 4.0e-04, 4.1e-04,\n",
       "        4.2e-04, 4.3e-04, 4.4e-04, 4.5e-04, 4.6e-04, 4.7e-04, 4.8e-04,\n",
       "        4.9e-04, 5.0e-04, 5.1e-04, 5.2e-04, 5.3e-04, 5.4e-04, 5.5e-04,\n",
       "        5.6e-04, 5.7e-04, 5.8e-04, 5.9e-04, 6.0e-04, 6.1e-04, 6.2e-04,\n",
       "        6.3e-04, 6.4e-04, 6.5e-04, 6.6e-04, 6.7e-04, 6.8e-04, 6.9e-04,\n",
       "        7.0e-04, 7.1e-04, 7.2e-04, 7.3e-04, 7.4e-04, 7.5e-04, 7.6e-04,\n",
       "        7.7e-04, 7.8e-04, 7.9e-04, 8.0e-04, 8.1e-04, 8.2e-04, 8.3e-04,\n",
       "        8.4e-04, 8.5e-04, 8.6e-04, 8.7e-04, 8.8e-04, 8.9e-04, 9.0e-04,\n",
       "        9.1e-04, 9.2e-04, 9.3e-04, 9.4e-04, 9.5e-04, 9.6e-04, 9.7e-04,\n",
       "        9.8e-04, 9.9e-04])}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ranges of hyper parameters that will be cross-tested in test_model_param\n",
    "param_grid = {\n",
    "    'C' : np.arange(0, 10, 0.01),\n",
    "    'tol': np.arange(0, 0.001, 1e-5),\n",
    "}\n",
    "# param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: LogisticRegression, seed:1\n",
      "train score: 0.9942908240473243\n",
      "test score: 0.9936545604622369 \n",
      "\n",
      "model (fs): LogisticRegression, seed:1\n",
      "train score: 0.9931386710689228\n",
      "test score: 0.9928807263722658 \n",
      "\n",
      "model: LogisticRegression, seed:1\n",
      "best parameters: {'tol': 0.0008600000000000001, 'C': 8.23}\n",
      "test score: 0.9942908272899839 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print scores for logistic regression\n",
    "test_model(LogisticRegression(max_iter=100000), X, y,seed=1)\n",
    "test_model_fs(LogisticRegression(max_iter=100000), X, y,seed=1)\n",
    "test_model_param(param_grid,LogisticRegression(max_iter=100000),X,y,seed=1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: RandomForestClassifier, seed:1\n",
      "train score: 0.9975409272252029\n",
      "test score: 0.9917457697069748 \n",
      "\n",
      "model (fs): RandomForestClassifier, seed:1\n",
      "train score: 0.9974893382858715\n",
      "test score: 0.9918489475856377 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print scores for random forest classifier model\n",
    "test_model(RandomForestClassifier(n_estimators=1000), X, y,seed=1)\n",
    "test_model_fs(RandomForestClassifier(n_estimators=1000), X, y,seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: RandomForestClassifier, seed:1\n",
      "train score: 0.9975409272252029\n",
      "test score: 0.991642591828312 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test with fewer trees\n",
    "test_model(RandomForestClassifier(n_estimators=100), X, y,seed=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3f8e71100435e7bad3de0247326fe2ee2f66761e6a4d6a3e4c67b492e2c5904b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
